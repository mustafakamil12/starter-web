================================================================= Master DevOps ==================================================

# important terms in that introduce by the Dark Lunching Technique and they lie at the heart of the devops
# also called DevOps life cycle phases
#- continuous monitoring	
#- continuous development	
#- continuous testing		
#- continuous integration
#- continuous deployment

===============================================================Start Of Git Phase=================================================

# git is tool and GitHub is the repository 

# to change the configuration file of git
$ git config

# to set the name in configuration file of git 
$ git config --global user.name "Al Ogaidi, Mustafa"

# to set the email in configuration file of git
$ git config --global user.email "godric.phoenix@gmail.com"

# to get a list of different configuration command for git 
$ git config --list

# to get help on git
$ git help

# to get help on a specific command
$ git help <command>

# to start new project with git u need to create new folder 
$mkdir <name>

# to create new repository in the project folder
$ git init

# to view the hidden repository in a directory 
$ ls -al

# to see changes and the commits in a repo, to verify the status of git project
$ git status

# to commit the changes in any file we need first to add these changes to the git project, to add all changes (before using the command below u will see this phrase <Untracked files> and file(s) in red color)
$ git add .
# after using the command above u will see this phrase <Changes to be committed> and file(s) in green color.

# to add changes in a specific file 
$ git add <file name>

# to commit changes, (-m  ==> message)
$ git commit -m "any text"
# after using the command above is u use git status u will get this message <nothing to commit, working tree clean>
# if we do any changes to the file above like adding some text and use git status u will get this message <Changes not staged for commit>

# if we need to see all the commits logs inside the git
$ git log

# if u need to see the commit log for a particular member inside the git
$ git log --author="member name"

# the git workflow is --> working area ==> staging area ==> repository


# if u wanna to use sublime text as git editor use the commands below <Please advise that the commands below for mac osx>
$ ln -s /Applications/Sublime\ Text.app/Contents/SharedSupport/bin/subl /usr/local/bin/.
$ echo $PATH
$ git config --global core.editor "subl -n -w"


# if u wanna to use Notepad++ as git editor in windows u ll use the steps below.
# first of all u need to add Notepad++ to the path in windows, if u didn't change the default path of the 
# installation u will find the notepad++.exe in <C:\Program Files (x86)\Notepad++>

# go to the search and look for environment variable.
# in environment variable --> system variables --> path --> new and put this path <C:\Program Files (x86)\Notepad++>

# now we need to configure notepad++ with bash, in ur project directory.
$ notepad++ .bash_profile  <-- if this file exist, it will create it, if not it will prompt u to create it.

# in the new page add the line below.
> alias npp='notepad++.exe --multilnst --nosession'

# now we need to configure notepad++ with git 
$ git config --global core.editor "\"C:\Program Files (x86)\Notepad++\notepad++.exe""  -multiInst -notabbar -nosession -noPlugin
# if u don't receive any error message that's mean it's good.

# now to verify if our work is ok 
$ cat ~/.gitconfig
$ git config --global --list
$ git config --global --e   <-- it's mean that i wanna to edit the config file.

# if u wanna to see the changes in ur repo area and ur working area, in another word the difference between local repo and local working area
$ git diff

# now to view the changes between staging area and repo
$ git diff --staged

# if u need to delete file in git, remove it from the working area using rm <file name>, or
$ git rm <file name>  --> if we using this command we will skip the next command since it will be staged already, we need to commit directly. 
$ git add .
$ git commit -m "message" 

# if u wanna to create a centralized repo in git hub
 -create new repo in GitHub
 -create new work area in ur computer
 -initialize the new work are using git init
 -copy the GitHub url using <clone>
 $ git remote add origin "GitHub url"
 -pull the changes from the GitHub
 $ git pull origin <branch>

 - if there's any issue with pull related to the history u can use this command.
 # go pull origin master --allow-unrelated-histories 

 -push the changes from local repo to GitHub
 $ git push origin master
 -we need to keep our local repo up to date with centralized repo.

# to create new branch <which is only a pointer not a real repo> use the following command
 $ git branch <branch name>

# now to switch the branch <after creating new branch>
$ git checkout <branch name>

# to view branches in git
$ git branch   or git branch -a

# file created in a branch <not master> will not been seen in master until merge.
# after ensure that everything in the branch is ok u can merge the branch with master.
# if u wanna to push the content of a branch to GitHub please push it to a branch, even if it's not exist in the GitHub yet.

# if u wanna to merge with a specific branch for ex master, u need first to git checkout to the master and then use this command.
$ git merge <branch name>  <-- if only move commits from branch to another u can see <Fast-forward just move the pointer>
$ git push origin <branch name>   <--- GitHub

# to remove file from staging area and get it back to the working area
$ git reset HEAD <file name>

# to revert a commit from the local repo, changes will be back to the working area.
$ git reset HEAD~

# if u wanna to remove .git folder from ur project
$ rm -rf .git

# fork in GitHub mean create that target repo in ur private space or personal repo.

# to clone project from GitHub to our local work area.
$ git clone <url from github>

# to open commit file, it's best to connect it with text editor
$ git commit

# general notes when u use git  1. use add for any untracked files --> 2. commit them to local repo --> 3. pull the latest update from the centralize repo --> 4. use push

# to discard changes in file before staging, use
$ git checkout -- <file>

# if u wanna to remove file for example after u already commit all changes and for some reason u wanna to get it back
$ git rm <file name> ---> this will remove file from staging area as well working area !!!.
$ git reset HEAD <file name>
$ git checkout -- <file name>

# now if we remove file directly from the system <not using git>
$ rm <file name> 
$ git reset HEAD <file name>
$ git checkout -- <file name>

# now if u wanna to delete a tree of folders with files included.
$ git rm -rf <directory name>  ---> recursively delete
# when commit the change above it can't be get back.

# to rename file in git project
$ git mv <old file name> <new file name>

# there's different between using mv as os command and git mv, in the using of <mv> it will working only on the working area by delete the old named file and create new one. conversely the git mv will working on both working area and staging area as well, by rename the file from old name to the new name.


# to get more graphical and decorated view for git log we can use the command
$ git log --oneline --graph --decorate --all

# to search log for specific date use
$ git log --since="2 days ages"   <--- example

# if u wanna to find changes that been done for a specific file
$ git log -- <file name>

# now if u wanna to get details about any commit
$ git show <commit id, even the first 7 chars>

# to create alias for any long command <to make long command short>s
$ git config --global alias.<name> "command options>
$ git <alias name>  <-- how to use alias
$ git config --global alias.history "log --all --graph --decorate --oneline"  <== to use this alias $ git history

# for example if u wanna to do some change in the alias command after u create it. let say u need to remove --graph from it.
# u need to edit the config file 
$ nano ~/.gitcofig

# if u wanna to exclude the unwanted files in git
#- create hidden file called <.gitignore>
#.git ignore pattern:
#- <file name>
#- <*.123>
#- <folder name/>
$nano .gitignore

# if u face any issue with .gitignore file like git don't ignore what u put in the .gitignore file
$ git rm -r --cached .
$ git add .
$ git commit -m "fixed untracked files"

# if u wanna to create access.log file
$ nano access.log
# it will contain the following:
#- /status 200
#- /httpaccess 200
#- /mktsp 300
#- /dummy 3000

# if u wanna to create error.log file
$ nano error.log
#- Authen error response code is 400
#- Not able to connect to server
#- State elemnet reference
#- Array out of bound index

# now to exclude all .log file(s) from  git project
$ nano .gitignore
# *.log  <-- add this to .gitignore
 
# to compare a specific file between working area and staging area.
$ git diff <file name>

# to compare the changes between working area and repo
$ git diff HEAD <file name > <--- file name is optional

# to compare the changes between staging area and repo
$ git diff --staged HEAD <file name>

# to compare the changes between 2 commits
$ git diff <commit id 1> <commit id 2>

# to compare the changes between the last commit and -1 the last commit <previous the last commit>
$ git diff HEAD HEAD^

# to list all branches in the git as well the remote repo and branches.
$ git branch -a 

# to delete branch from git locally, but u need to be not in this branch
$ git branch -d <branch name>

# if u wanna to rename the branch
$ git branch -m <old branch name> <new branch name>

#if u wanna to add message with merge process
$ git merge <branch1> -m "Some Text"

# if u got this error message <CONFLICT (content): Merge conflict in file name> that's mean we have conflict issue in this file.
# to resolve the conflict issue above u need to edit the file and update it.
$ git merge --abort

# git rebase is re-writing the project history by creating brand new commits for each commit, so it's move the entire feature branch to beginning on the top of the master branch.

# u can create new branch by using 
$ git checkout -b <branch name>

# u can do both staging and commit at the same time
$ git commit -am "text"

# to rebase branch
$ git checkout <Feature_Branch>
$ git rebase <target branch>

# if we have any rebase conflict, first thing u need to do is to abort the mission.
$ git rebase --abort

# to find difference between branch and another branch
$ git diff <branch1> <branch2>

# to continue rebase process
$ git rebase --continue

# to skip the current patching in rebase process
$ git rebase --skip

# if u modify anything in the remote repo and u wanna to see this modifying reflected to the local repo
$ git fetch   <--- it will fetch out all the changes which present in the remote repo but not present in ur local machine

# must likely u'll see this message <Your branch and 'origin/master' have diverged,> that's mean remote repo and local repo are not in sync.
# now the question in the case above how we can rebase the local repo with remote repo, to pick all the changes that we have in the local repo (the local branch) and put it on the head of the changes in the remote branchs.
$ git pull --rebase origin master.

# this phrase (HEAD -> master, origin/master, origin/HEAD) mean both local and remote repo in sync.

# if u wanna to stash ur work and work with another urgent thing.
$ git stash 

# stash commands , Keep in ur mind stash working on staged area only. 
#- git stash 
#- git stash apply
#- git stash list
#- git stash drop

# if u wanna to know if there's any changes in the stash file
$ git stash list

# WIP = Working In Progress

# if u wanna to apply stash changes to ur working directory.
$ git stash apply

# after revert changes from the stash u need to drop it, otherwise it will confuse u. 
$ git stash drop

# to list files that tracked by git
$ git ls-files

# to stash untracked files or changes
$ git stash -u

# to stash all files
$ git stash -a

# to apply all stashed use
$ git stash pop

# to do stash with message, so u can use it later.
$ git stash save "Change in simple.html - stash with message"  <--- Error: Cannot save the current work-tree state

# to see what actully in a specific stash (if we have multiple stashs) use
$ git stash show stash@{index#}

# if u wanna to apply specific stash on ur working dirctory.
$ git stash apply stash@{index#}
# remember to drop the specific stash # after using the command above.

# if u decide to clean stash queue <for example not needed > use
$ git stash clear

The upcoming scenario is to use one file in stage area, two files in working area, one file untracked.

# to add your stash to new branch.
$ git stash -a
# Please delete this file <sh.exe.stackdump>
$ git stash branch <branch name>

# to use git tagging we have multiple commands
$ git tag <tag name>
$ git tag --list  
$ git tag --delete <tag name>

# to create tag with some kind of message, annotated, we can use.
$ git tag -a <tag name>  ---> it will open editor to put ur message.

# to view the tag notes or message,
$ git show <tag name>

# to compare particular tags
$ git diff <tag name1> <tag name2>

# if u wanna to update specific commit in history
$ git tag -a <tag name> <commit id>

# if u wanna to update tag, if by mistake u tagged the wrong commit.
$ git tag -a <tag name> -f <new commit id>

# in case u put wrong message with git commit and u wanna to fix it.
$ git commit --amend -m <new message>

# to modify the old commit message
$ git rebase -i HEAD~3

# if u wanna after the target commit ID, all the file or changes will move to staging area.
$ git reset --soft <commit id>

# if u wanna after the target commit id, all the file or changes will move to the working area.
$ git reset <commit id>

# No data will left for recover.
$ git reset --hard <commit it>

# if we use reset --hard and we wanna to recover and track the changes that had been lost because of this reset. <about 30 days>
$ git reflog  <--- by this command u can review the reference log for git and find the commit id that u need to recover :)

# to move the git HEAD to specific commit id
$ git checkout <commit id>

# if for any reason have a lot of files and directories that had been created at some time in the git project directory and they are untracked files.
# if we need to clean or git project directory.
$ git clean -df

================================================================End Of Git Phase==================================================

=============================================================== Build Tool: Maven=================================================

# there are many build tools, maven, gradle and ant. we will use maven in this course

# to verify if the maven is already installed in ur machine.
$ mvn -v

# if the command return back any data that's mean it's already installed, if not that's mean it's not installed yet
# to install maven u need to check first if the java already installed and running in ur machine.
$ java -version

# then go to google to download the binary type of maven <apache-maven-3.6.1-bin.tar.gz> for example.
# unzip the file above.
# move the unzipped file to Applications
$ mv apache-maven-3.6.1 /Applications/
$ cd /Applications

# now we need to configure maven on this machine.
#- we need to create environment variable <M2_HOME> inside the bash profile.
$ cd /Users/mustafaalogaidi/
$ ls -a  ---> coz the bash profile is a hidden file. we are looking for this file <.bash_profile>
$ open -e .bash_profile

# add the line below to the profile...
> export M2_HOME=Applications/apache-maven-3.6.1
> export PATH=$PATH:$M2_HOME/bin
# now save the changes that u put in the bash profile and close it.
# to check that all changes had been saved.
$ cat .bash_profile

--------------------------------------------------------------------Example--------------------------------------------------------

# to create project with maven
# create new directory for the new project !!!
$ mkdir <dir name>
$ mvn archetype:generate  <--- this command will download the templates of maven project on ur machine.

# for our example we will hit enter for the most options except the options below:
#- groupId, Value: com.testing.sample
#- artifactId, Value: MySampleMavenProject  <-- project name
#- version, Value: 1.0-SNAPSHOT

# if pom.xml file deleted form the project, this project will not be compiled. it's the heart of the project.

# inside the project u will see also <src> folder, in side this folder u will see 2 folders <main> and <test>
#- main folder is dedicated for developing code.
#- test folder is dedicated to unit test code.

# now at this point it's mandatory to import this project to eclipse but before we need to do some change to make it compatible with eclipse, by fire some commands to ensure this.
$ cd MySampleMavenProject
$ mvn eclipse:eclipse

# to check if the process above success use
$ ls -a  ==> u should see these files <.classpath and .project> if so that's mean the project is ready to be imported into eclipse.

# go to eclipse --> file --> import --> general --> existing project into workspace --> next --> brows for ur project --> finish

# maven build life cycle

#- validate, to validate the structure of the project that had been generated by maven.
# u need to be inside the project directory.
$ ls -l  ==> u will also see new directory here <target>
$ cd /Users/mustafaalogaidi/Desktop/JavaProjectTraining/MySampleMavenProject
$ ls
$ mvn validate

#- compile
# we will remove the default classes in the project under main and test and will create new java classes.
$ mvn compile

#- test
$ mvn test

#- package
$ mvn package

# to verify that our project had been built...
$ cd target  <-- and u will find this for ex = MySampleMavenProject-1.0-SNAPSHOT.jar

#- clean
$ mvn clean

# all dependencies and support plugins are defined in the pom file.
# all dependencies resolved during the compilation which mentioned in pom file.

# if u wanna to add another dependency to ur project, u will add this in the pom file in the part of <dependency> for example <log4j maven>
# from google search about <log4j maven> 
# go to the site and u can select for example <Apache Log4j » 1.2.16>
# then copy the dependency. 
# inside the dependencies in pom file paste the dependency above. :)

$ mvn clean package

# after the command above u need to check the Referenced libraries, if u don't see the library above no problem, u can follow the steps below to check. 
# go to the eclipse --> <my project> --> R.C. ---> properties --> java build path --> libraries --> double click on the M2_Repo... to find the path.

$ cd /Users/mustafaalogaidi/.m2/repository
$ ls
$ cd log4j/
$ cd log4j/
$ ls  --> u can see this version 1.2.16

#- install  <-- not used yet and need to check google to find out how we can use this command!!!
$ mvn install

++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ Python with Maven +++++++++++++++++++++++++++++++++++++++++++++++++

# in eclipse --> help --> install new software --> work with <http://pydev.org/updates> --> Enter --> select pydev
# after installation and restart eclipse complete --> file --> new --> other --> pydev --> pydev project --> click on please an interpreter before proceeding
# --> <add the path to the python> for example </anaconda3/bin/python3.6> 
# after finish the process above select the interpreter and ok

# please advise that this part still under development, there's another plugin can be used!!!


=========================================================== End Build Tool: Maven ================================================

=================================================================== Jenkins ======================================================


------------------------------------------------------------Install Jenkins on Linux----------------------------------------------

# the only pre-request to install jenkins is java, it must be installed on the machine we will use linux ubuntu.

# to check ubuntu version
$ lsb_release -a

# verify java on a machine 
$ java --version

# to install java in order to execute jenkins war file we will use these commands
$ sudo add-apt-repository ppa:webupd8team/java   <-- I have issue with this command 
$ sudo apt-get update
$ sudo apt-get install oracle-java8-installer
$ sudo apt-get install oracle-java8-set-default

# working with linux later since we have an issue with one of the commands above

------------------------------------------------------------Install Jenkins on Windows---------------------------------------------

# download jenkins for windows from  --> https://jenkins.io/download/
# in the jenkins official site u'll note that there's 2 options:
#- LTS is mean Long-Term Support --> that's mean it's stable version.
#- weekly is mean not sure it's completely tested and ready.

# from the LTS down load --> Generic java package (.war)
# although we have a windows option but we will download (.war) file to use jenkins as a service in our machine.

# copy the downloaded file <jenkins.war> to any folder u want for example <c:/jenkins_server/jenkins.war>.

# now we need to check if java exist in our machine.
> java -version  --> it must be 1.8.x 

# if u wanna to open command prompt in a specific folder 
> target folder > address bar above put cmd and hit enter!!! :)
> java -jar jenkins.war --httpPort=9090  --> if it's running successfully u'll get this prompt
# <INFO: Jenkins is fully up and running>
# in case u need to use the default port for jenkins which is 8080, use the command above like follow:
> java -jar jenkins.war    :)

# now to access jenkins u need to use ur computer ip
> ipconfig

http://<urip>:9090

# now u'll prompted to enter adminstrative password, that u get it from 
$ cat <C:\Users\v435431\.jenkins\secrets\initialAdminPassword>  <---for example
> in this project our url will be http://10.248.238.51:9090/

# u need to install the suggested packages.


------------------------------------------------------------Install Jenkins on MAC----------------------------------------------

# download jenkins for MacOs from  --> https://jenkins.io/download/
# in the jenkins official site u'll note that there's 2 options:
#- LTS is mean Long-Term Support --> that's mean it's stable version.
#- weekly is mean not sure it's completely tested and ready.

# from the LTS down load --> Generic java package (.war)
# although we have a MacOs option but we will download (.war) file to use jenkins as a service in our machine.

# copy the downloaded file <jenkins.war> to any folder u want for example </jenkins_server/jenkins.war>.

# now we need to check if java exist in our machine.
$ java -version  --> it must be 1.8.x , Or u can use the command below
$ javac -version

# to run jenkins u need to submit the command below
$ java -jar /jenkins.war --httpPort=9090  --> if it's running successfully u'll get this prompt
# it will start unpackaged the war file
# it will create directory <.jenkins> in user home directory
# <INFO: Jenkins is fully up and running>

# now to access jenkins u need to use ur computer ip
$ ifconfig

http://<urip>:9090

# now u'll prompted to enter adminstrative password, that u get it from 
$ cat </Users/mustafaalogaidi/.jenkins/secrets/initialAdminPassword>  <---for example
# or through the unpacking process above u will get prompt said <please use the password below> !!! :)
> in this project our url will be http://10.120.65.233:9090/

# u need to install the suggested packages.


----------------------------------------------------------Start Working With Jenkins--------------------------------------------

# start ur jenkins server using
$ java -jar jenkins.war <--httpPort=9090>    --> port is optional default port is 8080
> localhost:9090

# in the jenkins menu side
#- new item = create new job --> used to start new job.
#- people used to configure users and groups. 
#- Build history will be used to get build history of the job.
#- manage jenkins is used for manage plugins and many other configuration.
#- my viwe is used to create my own dashboard.
#- to create new view for urself.

# at this poing we will select the FreeStyle Project, which is the most flexible template in the Jenkins

# in the job configuration 
#- General
 #-- Discard old builds, it's used to discard old builds.that's mean to remove old builds of the job from build history.
 #-- GitHub project, we need to provide github url from where we need to pull the code once we execute the job.
 #-- This build requires lockable resources, 
 #-- This project is parameterized, if the project accept parametrs we can provide these parametrs here.
 #-- Throttle builds, this option will be used to set the maximum build in parallel per a specific period.
 #-- Disable this project, if this option set, that's mean nobody will be able to execute this project.
 #-- Execute concurrent builds if necessary, <Please keep this check box checked>, it's allow morethan one job in a paralle in the same time.
#- Source Code Management
 #-- None
 #-- Git, we need to provide git url with creds as well.
 #-- Subversion, use to pull code from the SCM like apache subversion.
 # if u need to use another source code not in the list then u need to install it's plugin. :)
#- Build Triggers
 #-- Trigger builds remotely (e.g., from scripts), by this option i can trigger build remotely from another servers, using some kind of scripts or commands.
 #-- Build after other projects are built, this particular build will be triggered after specific build had been execution.
 #-- Build periodically, to build project periodically for a specific given period.
 #-- GitHub hook trigger for GITScm polling, this option will be work when u enable Git opotion, whene ever u push something it will trigger build project.
 #-- Poll SCM, using scm to trigger build project.
#- Build Environment
 #-- Delete workspace before build starts, it's mean clean the previous workspace.
 #-- Use secret text(s) or file(s)
 #-- Abort the build if it's stuck
 #-- Add timestamps to the Console Output
 #-- Inspect build log for published Gradle build scans
 #-- With Ant
#- Build, used to add build steps
#- Post-build Actions, used to perform some actions when the build complete.

# Example: Jenkins-Staging-First-Job
 - General --> <Execute concurrent builds if necessary>
 - Build --> Execute Shell <echo This is my first Jenkins job>

--------------------------------------------------Installing Git and GitHub plugin on Jenkins-----------------------------------


# --> manage jenkins --> manage plugins --> available --> in the filter put <Github> --> we will select Github integration --> install without restart
# if u upgrade plugin please select <Download now and install after restart>, by this way it will not impact ur execution.
# if u wanna to check if the plugin was installed, manage jenkins --> manage plugins --> installed 

# now we need to configure maven with jenkins, to do this 
--> manage jenkins --> global tool configuration --> --- JDK 
							    |    |_ name  = localJDK
							    |    |_ JAVA_HOME = C:\Program Files\Java\jdk1.8.0_201  <-- Windows
						    	|    |_ JAVA_HOME = /Library/Java/JavaVirtualMachines/jdk1.8.0_201.jdk/Contents/Home  <-- Mac
							    |
							    |--- Git
							    |    |_ name = localGit
							    |	 |_ Path to Git executable = C:\Users\v435431\AppData\Local\Programs\Git\bin\git.exe
							    | 	 |_ Path to Git executable = /usr/local/bin/git  <-- Mac
						        |     
							    |___ Gradle
							    |    |_ name = localGradle
							    |	 |_ GRADLE_HOME = 
							    | 	 |_ GRADLE_HOME = /usr/local/bin/  <-- Mac
							    |
							    |___ Maven
							         |_ name = localMaven
							    	 |_ MAVEN_HOME = C:\Users\v435431\Desktop\Pivotal\apache-maven-3.6.0\
							     	 |_ MAVEN_HOME = /Users/mustafaalogaidi/Downloads/apache-maven-3.5.3/ <-- Mac
							    


# for our example <Sample-Maven-Project> when we run build project it's failed at first time, coz jenkins couldn't find the pom.xml file, so we provide, hard coded the pom.xml path --> </Users/mustafaalogaidi/.jenkins/workspace/Sample-Maven-Project/java-maven-junit-helloworld-master/pom.xml>
# to resolve this issue, coz if we try to build this project from another machine like linux, it will failed also, so to resolve this issue use
<$workspace/java-maven-junit-helloworld-master/pom.xml>

# if u put this <* * * * *> in the poll scm in build triggers, this mean check the repo every minute and build if there's any change...

# Trigger builds remotely, we can use any kind of string not include ? or %. for example <mustafakamil>
# example of url --> JENKINS_URL/job/Sample-Maven-Project/build?token=TOKEN_NAME
# u need to do some change to the url above to be --> localhost:9090/job/Sample-Maven-Project/build?token=mustafakamil
# if ur jenkins is ldap secure it will ask for username and password to trigger the build.

# Build after other projects are built, u can use project or multiple project separated by comma. 

# GitHub hook trigger for GITScm polling, it's mean if any developer commit any changes that will trigger the build job asap. but we need first to setup GitHub hook!

# to check the code quality with Jenkins we will use check style report ---> used for java.

# to add the check style report, we need to add this in the build section for ur project. --> goals --> clean install checkstyle:checkstyle
# also u need to select something in the post-build Actions section --> publish checkstyle analysis result.

# there's also another good plugins for code quality check for java  developer like PMD , FindBugs 

# to archive artifact in jenkins --> configuration --> Post-build Actions --> archive artifact --> use **/* <which is mean all files in the workspace>  or only jar like **/*.jar

# <Project Sample-Maven-Project> configuration:-

 - General -- Discard old builds -- Strategy --> Log Rotation
							    |- Days to keep builds --> 2
							    |- Max # of builds to keep --> 5

 - Source Code Management -- Git -- Repository URL --> https://github.com/mustafakamil12/Jenkins.git
 - Build -- Invoke top-maven level maven projects -- Maven Version --> LocalMaven
 												  |- Goals --> 	clean install checkstyle:checkstyle

 - Post-build Actions -- [Deprecated] Publish Checkstyle analysis results
 					  |- archive the artifacts <**/*.jar>


--------------------------------------------------------Installing Tomcat as staging env.---------------------------------------


# Tomcat is an open source web-server and provides a pure java http web server environment in which java code can run.

# we need to install Tomcat in ur computer

# Tomcat default port is = 8080

# cd /Users/mustafaalogaidi/Downloads/apache-tomcat-8.5.29/apache-tomcat-8.5.29-staging/bin

# to start tomcat 

$ ./startup.sh

# to stop tomcat

$ ./shutdown.sh 

# to avoid the conflict of ports between jenkins and tomcat we need to do some change, go to the <conf> directory for the tomcat.
# </Users/mustafaalogaidi/Downloads/apache-tomcat-8.5.29/apache-tomcat-8.5.29-staging/conf>
# find the file name server.xml
# in the server.xml look for <connector> under service name <catalina>
# we used in our tomcat, port = 8081
# now use this url <localhost:8081>

# now go to ur project directory and build the project with maven. 

$ mvn clean package

# after build complete u need to copy the war file in the target directory to the tomcat directory in <webapps> directory.

# restart tomcat again.

# in the url use <http://localhost:8081/java-tomcat-maven-example/index.jsp>

# if u make any change in the file index.jsp for example to test how the tomcat will behave, it will reflect nothing until u build the project again.
# then u need to copy the war file to the tomcat ---> webapps again, also u need to restart tomcat :) and then u can see the changes...:)

# now we need to get jenkins do the rest of the job here, I mean to start stop and restart Tomcat, so we need first some creds to make the jenkins deploy the call.

# the target file is in /tomcat/conf/tomcat-users.xml  --> go to the end of the file.

# if the <role rolename  is commented please remove comment.

# roles must be look like below

  <role rolename="manager-script"/>
  <role rolename="admin-gui"/>
  <user username="tomcat" password="tomcat" roles="manager-script,admin-gui"/>

# in jenkins we need to add more 2 plugins, they will be used to deploy artifacts.
 #- copy artifact
 #- deploy to container

# if u forgot ur jenkins username and password go to 
$ cd /Users/mustafaalogaidi/.jenkins/users/mustafa_6337081533390694085
$ subl config.xml
# u can see the username but the password is already encrypted u can bypass this issue by modifying the <config.xml> in the <.jenkins> directory
<useSecurity>true</useSecurity>  ==> <useSecurity>false</useSecurity>

# keep in mind that u will create first job which is responsible for creating and deploy war file, then we need another job to deploy this war file to tomcat.

# in our example we will use <Packer_Servlet_Project> --> <Deploy-Servlet-Staging-Env> ---------> <Deploy-To-Prod>
													  |_> <Static Analysis-Servlet Application>

 <<Packer_Servlet_Project>> configuration:-
 - General -- Discard old builds --> true
 		   |- Strategy -- Log Rotation 
           |- Days to keep builds -- 2
           |- Days to keep builds -- 5

 - Source Code Management -- Git -- Repositories --> <https://github.com/mustafakamil12/java-tomcat-maven-example.git>
 - Build Environment -- Delete workspace before build starts
                     |- Add timestamps to the Console Output

 - Build -- Invoke top-level maven targets -- Maven Version -- localmaven
                                           |- Goals -- clean package

 - Post-build Actions -- archive the artifacts -- Files to archive  --> **/*.war
 (parllel builds type) |- build other projects  -- Projects to build --> Deploy-Servlet-Staging-Env,Static Analysis-Servlet Application
                      						    |- Trigger only if build is stable

 <<Deploy-Servlet-Staging-Env>> configuration:
 - General -- Discard old builds --> true
 		   |- Strategy -- Log Rotation 
           |- Days to keep builds -- 2
           |- Days to keep builds -- 5

 - Build Environment -- Delete workspace before build starts
                     |- Add timestamps to the Console Output

 - Build -- copy artifacts from another project -- Project name -- Packer_Servlet_Project
 											    |- Which build -- Latest successfull build
 											    |- Stable build only
 											    |- Artifacts to copy -- **/*.war
 											    |- Fingerprint Artifacts

 - Post-build Actions -- Deploy war/ear to container -- WAR/EAR files -- **/*.war
 					  |								 |- Containers -- Tomcat 8.x Remote -- Credentials -- tomcat/*****
 					  |								                                    |- Tomcat URL  -- http://localhost:8081
 					  |
 					  |- build other projects (manual steps) -- Downstream Project Names -- Deploy-To-Prod
 					  

 
 <<Static Analysis-Servlet Application>> configuration:
 - Source Code Management -- Git -- Repositories -- Repository URL --> https://github.com/mustafakamil12/java-tomcat-maven-example.git
 												  
 - Build -- Invoke top-level maven targets -- Maven Version -- localmaven
                                           |- Goals -- checkstyle:checkstyle

 
 <<Deploy-To-Prod>> configuration:
 - General -- Discard old builds --> true
 		   |- Strategy -- Log Rotation 
           |- Days to keep builds -- 2
           |- Days to keep builds -- 5

 - Build -- copy artifacts from another project -- Project name -- Packer_Servlet_Project
 											    |- Which build -- Latest successfull build
 											    |- Artifacts to copy -- **/*.war
 											    |- Fingerprint Artifacts

 - Post-build Actions -- Deploy war/ear to container -- WAR/EAR files -- **/*.war
 					    							 |- context path --> /
 					   								 |- Containers -- Tomcat 8.x Remote -- Credentials -- tomcat/*****
 					  								                                    |- Tomcat URL  -- http://localhost:9095/
 
 	 				  

---------------------------------------------------------------Build Pipelines--------------------------------------------------

# if u wanna to build a pipeline u can flow up the steps below:-

# --> new view --> <PipeLine> --> Build Pipeline view --> 
													  |- Name -- PipeLine
													  |- Pipeline flow -- Layout -- Based on upstream/downstream relationship
													  |                |- Upstream / downstream config -- Select Initial Job --> Packer_Servlet_project  <-- where's the parent job :)
													  |- Trigger Options -- Build Cards -- standard build card
													  |- Display Options -- No Of Displayed Builds --> 1
													                     |- Row Headers --> just the pipeline number
													                     |- Refresh frequency (in seconds) --> 3
													                     |- Console Output Link Style --> Lightbox


--------------------------------------------------------------Pipelines as Code-------------------------------------------------


# the target is to maintain and execute our pipeline with the help of code.
# keep in mind the code will be used is groove and python.
# pipeline code use DSL <Domain Specific Language>
# now to create any jenkins code base file we will use the tree below for now.

pipeline {
    agent any 										  <-- agent mean the jenkins node, any mean any available node. <parent job>
    stages {

    	agent abc 						     Optional <-- in some cases we need to define specific node for specific stage, in this one we use <abc> (this is a child job)

        stage ('Initialize') {
            steps {
                echo  "Initializing the Code File"    <-- anything can be in the steps...
            }
        }

        stage ('Build') {
            steps {
                echo 'Hello World'				      <-- anything can be in the steps...
            }
        }

        agent xyz						     Optional  <-- in some cases we need to define specific node for specific stage, in this one we use <xyz> (this is a child job)

         stage ('Deploy') {
            steps {
                echo 'Deployed an Artifact'           <-- anything can be in the steps...
            }
        }
    }
}

# if u see this command in the steps < sh ''' > that's mean it's a shell file.
# after creating the new file, u need to push this file to git hub.
# now before start working on jenkins file inside jenkins, we need to ensure that pipline plugin already installed <on installed tab> in the jenkins.
# at this time we will not going to select <Freestyle Project> but we are going to select <Pipeline>
# when u add new stage, at jenkins u can notice that there's no history for the new stage that had been added.

# now we will going to code the pipeline for packer_servlet_project.
# first of all the packer_servlet_project is a free style project, now we need to convert this to a pipeline project.
# the best way to do this is create new project rather than convert the existance one. 

# in this case we will select <Pipeline> instead of <Freestyle Project>

# take a look on the code below

pipeline {
    agent any
    stages {
        stage ('Build Servlet Project') {
            steps {
                /*For windows machine */
                //bat  'mvn clean package'

                /*For Mac & Linux machine */
               sh  'mvn clean package'
            }

            post{									  <-- This line mean post-build action
                success{							  <-- This is a condition, if the build success start execute the lines below.
                    echo 'Now Archiving ....'

                    archiveArtifacts artifacts : '**/*.war'
                }
            }
        }

# for more detail about the jenkins file and how u can use it please see this url <https://jenkins.io/doc/book/pipeline/jenkinsfile/>

# the code below is a real pipeline 

pipeline {
    agent any
    stages {
        stage ('Initialize') {
            steps {
                echo  "Initializing the Code File"
            }
        }

        stage ('Build') {
            steps {
                echo 'Hello World'
            }
        }

         stage ('Deploy') {
            steps {
                echo 'Deployed an Artifact'
            }
        }

    }
} 

<Packer_Servlet_Pipeline> configuration:     <-- Pipeline
 - General -- Discard old builds --> true
 		   |- Strategy -- Log Rotation 
           |- Days to keep builds -- 2
           |- Days to keep builds -- 5


 - Pipeline -- Definition --> Pipeline script from SCM
 						  |-  SCM -- Git
 						  |-  Repositories -- Repository URL
 						  |                |- https://github.com/mustafakamil12/java-tomcat-maven-example.git
 						  |
 						  |- Script Path -- Jenkinsfile_test
 						  |- Lightweight checkout -- true



<Deploy-StagingArea-Pipeline> configuration:  <-- Freestyle project
 - General -- Discard old builds --> true
 		   |- Strategy -- Log Rotation 
           |- Days to keep builds -- 2
           |- Days to keep builds -- 5

 - Build Environment -- Delete workspace before build starts
 					 |- Add timestamps to the Console Output

 - Build -- copy artifacts from another project -- Project name -- Packer_Servlet_Pipeline
 											    |- Which build -- Latest successfull build
 											    |- Stable build only
 											    |- Artifacts to copy -- **/*.war
 											    |- Fingerprint Artifacts

 - Post-build Actions -- Deploy war/ear to container -- WAR/EAR files -- **/*.war
 					  |								 |- Containers -- Tomcat 8.x Remote -- Credentials -- tomcat/*****
 					  |								                                    |- Tomcat URL  -- http://localhost:8081
 					  |
 					  |- build other projects (manual steps) -- Downstream Project Names -- Deploy-To-Prod   <-- may be need to remove
 					  


 <Deploy-To-Prod> configuration:
 - General -- Discard old builds --> true
 		   |- Strategy -- Log Rotation 
           |- Days to keep builds -- 2
           |- Days to keep builds -- 5

 - Build -- copy artifacts from another project -- Project name -- Packer_Servlet_Pipeline
 											    |- Which build -- Latest successfull build
 											    |- Artifacts to copy -- **/*.war
 											    |- Fingerprint Artifacts

 - Post-build Actions -- Deploy war/ear to container -- WAR/EAR files -- **/*.war
 					    							 |- context path --> /
 					   								 |- Containers -- Tomcat 8.x Remote -- Credentials -- tomcat/*****
 					  								                                    |- Tomcat URL  -- http://localhost:9095/
 

# now let's create new view 

# --> new view --> <Pipeline as Code> --> List View -- jobs -- Packer_Servlet_Pipeline
															|- Deploy-StagingArea-Pipeline
															|- Deploy-To-Prod-Pipeline



# we had been create 2 jobs one was <Deploy-Servlet-Staging-Env> and the other one was <Deploy-Servlet-Staging-Env>, now we have 2 choices here,
# either we going to use the old jobs or create new jobs for the pipeline as code.
# here we are going to create new jobs :)
# when u create new job and u need this new job to be like a copy of an existin job, just use the <copy form> in the bottom of the creating page...
# for staging job we will change only the <project name> in <build environment tab> to our pipeline project.
# u also need to add the new job to ur pipeline view :)
# any job in the pipeline failed, all the pipeline will be marked as failed.
# sometime, when u do some changes to <index.jsp> for example and run the job in jenkins but u don't any changes reflected to the page, only u need to 
# restart the tomcat.

# to check any syntax for pipeline code check google <pipeline as code with jenkins>


-------------------------------------------------------------Distributed Builds-------------------------------------------------

-----------------------------------------------------------Create Master on Cloud-----------------------------------------------


# Master :
 1. Schedule Build Job
 2. Dispatches Builds to the Slave for Actual Job Execution
 3. Monitoring the Slave and recording the build Results.
# Salve :
 1. Execute Builds Jobs dispatched by master

# for this lesson, we are going to use <Digital Ocean> for testing our archeticture. we used digital ocean because it's easy to use. 

# Jenkins: way to start slave
 1. the master can start the salave agents via SSH.
 2. start slave manually using java web-start.
 3. install the slave agents as windows service.
 4. start the slave directly from command line on slave machine.

# when u login to digital ocean droplet, u need to use the command below, 
 $   wget -q -O - http://pkg.jenkins-ci.org/debian/jenkins-ci.org.key | apt-key add -  
 $   echo deb http://pkg.jenkins-ci.org/debian binary/ > /etc/apt/sources.list.d/jenkins.list     
 $   apt-get update     
 $   apt-get install jenkins

 #   the command above may be failed due to failed to install and start Jenkins then u need to use the command below
 $   apt-get install jenkins=2.67 
 
 #   if this command failed and the error message will be, ERROR: No Java executable found in current PATH: /bin:/usr/bin:/sbin:/usr/sbin, please use the command below.. 
 $   ps aux | grep java    <-- to verify if the java is running.
 $   systemctl status jenkins.service  <-- to ensure that the service is not startup.
 $   java -version   <-- to ensure that u have java installed in the machine.
 #   if the java is not found, then u need to install it in the cloud,
 $   sudo apt-get install default-jre
 $   sudo apt-get install default-jdk
 #   again u need to check the java if it's installed or not.
 $   java -version

 #   to start jenkins 
 $   systemctl start jenkins

 #   to stop jenkins
 $   systemctl stop jenkins

 #   to check jenkins status
 $   systemctl status jenkins

 #   to restart jenkins 
 $   systemctl restart jenkins

 ------------------------------------------------------------Create Slave on Cloud-----------------------------------------------


 # go to digitalocean and create another droplets

 # we will use the list of commands below
  $   sudo apt-get update
  $   sudo apt-get install default-jre
  $   sudo apt-get install default-jdk
  $   java -version

#  >>>>> Set-up Auto SSH Login <<<<<<<

1. Log-in master Node and run command :

 $ sudo -iu jenkins

2. Generate Public & Private RSA Key. Command:

 $ ssh-keygen -t rsa

 # public key location : /var/lib/jenkins/.ssh/id_rsa.pub
 # Private key location :  /var/lib/jenkins/.ssh/id_rsa


3. Create .ssh directory on slave from master node

 $ ssh root@<slave_ip> mkdir -p .ssh


4. Attach master public key with slave authorized directory

 $ cat .ssh/id_rsa.pub | ssh root@<slave_ip> 'cat >> .ssh/authorized_keys'



#  >>>>> Download Slave Agent Program on Slave Machine <<<<<<<

1. Create bin directory.

 $ mkdir ~/bin

2. Go to bin and download slave.jar from master

 $ cd bin 
 $ wget http://<master_ip>:8080/jnlpJars/slave.jar

 $ free -h  <-- to check the free space on ur machine.
 $ df -h    <-- to check all folders spaces..:)

# Now to add nodes to the master jenkins, --> manage jenkins --> manage nodes --> new node --> <we can use the same slave machine name>

# if the <Launch agent via execution of the command on the master> is not available in the launch method list that's mean <SSH plugin> not installed int the jenkins and u need to install it.

#  >>>>> Launch Command <<<<<<

 $ ssh root@<slave_ip> java -jar /root/bin/slave.jar 

# btw we have only <Freestyle project> because we didn't install any plugins, so this option is by default with jenkins.

# to test our works above we will create 6 jobs in each one we will use only build --> Execute shell --> sleep 10;

# to use labe if needed especially when u have special work to do with slaves not with master, 
# open master --> configure --> lable and put master.
# open slaves --> configure --> lable and put slave
# lable is case senstive.

# open all ur jobs --> configure --> general --> Restrict where this project can be run --> put slave   <-- for example and it's case senstive.
# run jobs one time and see what will happen. :)


=============================================================== End of Jenkins ===================================================


================================================================== BitBucket =====================================================

# Bitbucket : Bitbucket is a web-based version control repository hosting service owned by Atlassian

# we will learn these points
 # creating bitbucket account
 # creating a repository on bitbucket
 # downloading and installing a bitbucket desktop application
 # cloning ur first bitbucket repo to ur computer
 # creating ur first bitbucket commit
 # creating ur first push to bitbucket repo

# to create bitbucket account --> google --> search for bitbucket --> go to the site --> click on get start for free --> fill info

# now we need to create a repo --> dashboard --> repository --> create new repo --> 

# now for bitbucket app we will use <source tree> as app. u can download it from google.
# after installing the app, u need do some configuration.
# first thing we need is setting our account --> sourceTree tab --> prefrences --> accounts --> add --> connect account --> use ur account for bitbucket --> grant access
# now if u click on <local> button u'll not find anything so we need to go to next step.

# to clone repo from bitbucket to our computer --> click on <remote> button it will show u all repos created early. --> clone

# create a text file in the bitbucket folder on ur desktop, save it

# --> add file by click the check box --> click on <commit> button --> put message --> commit

# to push --> click on <push> button --> ensure that all options correct --> OK




============================================================== End of BitBucket ==================================================

=================================================================== GitLab =======================================================

# Gitlab is a service that provides remote access to Git repositories.
# You can install the GitLab runner on different operating systems,

# we will cover the installation on windows.
 − First create a folder called 'GitLab-Runner' in your system. For instance, you can create in C drive as C:\GitLab-Runner.
 - Now download the binary for x86 or amd64 and copy it in the folder created by you. Rename the downloaded binary to gitlab-runner.exe.
 - Open the command prompt and navigate to your created folder. Now type the below command and press enter.
 -> C:\GitLab-Runner> gitlab-runner.exe register
 − After running the above command, it will ask to enter the gitlab-ci coordinator URL.
 - Enter the gitlab-ci token for the runner.
 - To get the token, login to your GitLab account:
   * go to your project.
   * Click on the CI/CD option under Settings tab and expand the Runners Settings option.
   * Under Runners Settings section, you will get the token.
 − Enter the gitlab-ci description for the runner.
 − It will ask to enter the gitlab-ci tags for the runner. we are going to use tag1, tag2
 − You can lock the Runner to current project by setting it to true value.
 − Now enter the Runner executor for building the project. we will use ===> docker
 − Next it will ask for default image to be set for docker selector. we will used ==> alpine:latest
 − Now go to your project, click on the CI/CD option under Settings section and you will see the activated Runners for the project.
 - You can see the GitLab Runner configuration in the config.toml file under the GitLab-Runner folder

# for Mac we will use brew command as below
$ brew install gitlab-runner
$ brew services start gitlab-runner 

# there's another way to use gitlab, by using docker container --> this approach had been tested in mac

sudo docker run --detach --name gitlab \
--hostname gitlab.example.com \
--publish 30080:30080 \
--publish 30022:22 \
--env GITLAB_OMNIBUS_CONFIG="external_url 'http://gitlab.example.com:30080'; gitlab_rails['gitlab_shell_ssh_port']=30022;" \
gitlab/gitlab-ce:latest


================================================================ End of GitLab ===================================================


=================================================================== Packer =======================================================

# packer by HashiCorp.
# first we need to download packer from it's site, use google, it's a zip file, unzip the file and copy it to -->
# c:\program files\ --> create folder for packer.
# add packer path to the <environment variables>  
# now u need to check if the packer working 
$ packer version 

# for MacOs u need to use this command <$ brew install packer>

# to write a template u'll use json file.
# we will need also <install.sh> installation script file.

# keep in mind we need <aws-access-key> and <aws-secret-key> to communicate with amazon API.

# to use a specific image that u need --> AWS --> EC2 --> AMIs --> click on drop down list --> public --> images --> select one 
# keep in mind we will use <AMI-ID>

# now to build machine image
$ packer build <path of json file>

# now u need to check if the template working or not, create new EC2,
# --> EC2 --> lunch instance --> my AMIs --> review and lunch --> be sure that traffic allowed on port 80 open --> lunch


================================================================= End of Packer ==================================================

=================================================================== Terraform ====================================================

# it's an open source tool had been developed by HashiCorp,
# it's help you u to automate the implementation of the entire infrastructure using code.

# the first thing that u need is to write the configuration terra file and it's <.tf>, which use a hcl language <HashiCorp Configuration Language>

# terraform have 3 steps to do in order to build the infrastructure
 1. check against the current infrastructure
 2. what resources required 
 3. list out the resoureces the u need to create.

# if u trying to modify the current infrastructure, terraform will use to mostly the same steps.
 1. compare the current infrastructure with what's new in the new configuration file.
 2. apply changes.

# after installing terraform, u need to create a user in aws with proper authientication for terraform use.
--> aws --> IAM --> users --> add user --> <terraform-user> --> select proper group.

# next step u need to download, install and configure awscli. --> check the aws lessons :)

# now u need configure the profile in aws for <terraform-user> as below.

$ aws configure --profile terraform-user

 1. AWS Access Key ID [None]: 
 2. AWS Secret Access Key [None]: 
 3. Default region name [None]: us-east-1
 4. Default output format [None]: 

# now after we done with all required setting for terraform, we need to select the folder that will be our project folder.
 $ mkdir terraform
 $ touch production-application.tf

# go to terraform website --> docs --> provider --> in our example we are going to use shared credentials example.

# in our example where we create the <production-application.tf> in this path we need to use this command
 
  $ terraform init  --> to initilize the provider plugins and it will create folder with required configuration

# in our example we are not going to create the entire infrastructure as in the diagram, but we will do some of them.

# for example for load balancer we can go to the terraform site and look into the docs for <aws_alb>.

# btw in our example we didn't create the security group, we need to put this automatically in the code.

# for vlsm u can use this online calculator <http://www.vlsm-calc.net/>

# our example used from terraform course -- > section 2 --> lesson 3 and 4

# we will work with an example from the youtube to mix terraform and jenkins... :)

# requirements:

 - Workspace Cleanup Plugin
 - Credentials Binding Plugin
 - AnsiColor Plugin
 - GitHub Plugin
 - Pipeline Plugin
 - CloudBees AWS Credentials Plugin


 # we need to create some creds before start working on the project...
 tomcat --> username/password
 github --> secret text
 aws    --> aws credentials
 github --> username/password



<Terraform> configuration:   <-- Multibranch Pipeline
 - Branch Sources -- Github -- Credentials --> ur creds to login to Github in format of username/password
 						    |- Repository HTTPS URL -- https://github.com/mustafakamil12/mygitops.git
 						    |- Property strategy -- all branches get the same properties

 - Build Configuration -- Mode -- by jenkins
     				   |- script path -- Jenkinsfile

 - Orphaned Item Strategy -- Discard old items -- true




=============================================================== End of Terraform =================================================


>>>> All paths required for DevOpsd <<<<<

/Users/mustafaalogaidi/Desktop/java-tomcat-maven-example
/Users/mustafaalogaidi/Desktop/starter-web
/Users/mustafaalogaidi/Desktop/java-tomcat-maven-example/src/main/webapp
/Users/mustafaalogaidi/Downloads/apache-tomcat-8.5.29/apache-tomcat-8.5.29-prod/bin
/Users/mustafaalogaidi/Downloads/apache-tomcat-8.5.29/apache-tomcat-8.5.29-staging/bin
/Users/mustafaalogaidi/Desktop/Jenkins_Server

iterm
/Users/mustafaalogaidi/Desktop/terraform
/Users/mustafaalogaidi/Desktop/mygitops


==================================================================== Docker ======================================================

# Docker is a tool designed to make it easier to create, deploy and run applications by using containers.
# Docker containers are lightweight alternatives to virtual machines and use the host OS.
# You don't have to pre-allocate any RAM in containers 

														 .- Stable  <-- release every quarter 
								.- Community  --> Free --|
# there's 2 flavor for docker --| 						 .- edge release   <-- come with lates technologies not been tested yet/monthly
								.- Enterprise --> Paied


# docker edition available at <store.docker.com>

						.- CE = Community Edition
# docker abbreviation --|
						.- EE = Entrprise Edition

						  .- Linux   (naitivly support docker)
# major type of install --|- Mac/Win (set of toolbox)
						  .- Cloud   (AWS/Azure/Google)


# we will skip installing docker for windows for now.  <<<<<<<=========

# to install docker on mac all u need just go to store.docker.com and download docker, follow up instructions.
# to verify docker on ur terminal
$ docker version

# if u restart docker and run the command above u will see only the client info, since mac don't support docker natively.
# client is running on ur machine
# server is running on linux core.

-----------------------------------------------------------Create Machine on Cloud----------------------------------------------

# Digital Ocean
# Memory: 2GB , vCPUs: 2, Disk: 60GB, Transfer: 3TB  --> Name: DockerMachine

# this will be used as cloud for docker.
# ssh to the new machine using username and password the u got by email :)
# to double check that u r in the correct machine use
$ hostname

# we will skip installing docker for windows for now.  <<<<<<<=========

# we will skip installing docker for Linux for now.  <<<<<<<=========

--------------------------------------------------------------Docker Container--------------------------------------------------

# docker cli = docker client
# docker engine = docker server

* btw in this course he will use machine in cloud to run docker.

# to get the machine name
$ hostname

# to find the docker version
$ docker version

# to verify docker engin setup and details
$ docker info

# to list all docker commands
$ docker
# the result will come up wiht 2 segments of commands 

 - Management commands
 - commands  <-- early 2017 u will get only this segment.
# docker community relize that there's alot of commands and there's a confusion, so they split them to 2 segments. :)

# docker management commands format
# docker <command> <sub-command> (optional)

--------------------------------------------------------Start Working with Container--------------------------------------------


# --> Docker --> Container --> Image

# in this lec we will use open source Nginx web-server and docer central repository
# http://hub.docker.com   --> it's a centeral repo for to push our image or get public image.
# if u looking for official image u will see this lable on the image <official>

# now u need to execute this command.
$ docker info

# docker container run hello-world    <-- this command will look into local repo if the image not available it will pull the image from the docker hub.

# if u repeat the command above again u wil see that the image availabe in the local repo.

# now we need to run Nginx web-server in the docker 
# > docker container run --publish <host_port:container_port> <image name>
$ docker container run --publish 80:80 nginx

# to exit out of ur container just submit CTRL+C

# process behinde the sceen
 - download the image from docker hub
 - started new container
 - exposed port 80 on host machine
 - rout traffic to the container port 80

# keep in mind the command above will run on the forground.
# if u need to rung Nginx on the back ground.
# > docker container run --publish <host_port:container_port> --detach <image name>
$ docker container run --publish 80:80 --detach nginx 

# the command above will return a container id, for ex <84136aa7c786c92bd5c08c52f45e16da9c8ddf5a35809b28cefcd950012c27df>
# now check ur browser again to ensure that the nginx working 

# if u wanna to run another server with different port u can use 
$ docker container run --publish 8087:80 --detach nginx   <-- example
<9d258d465b37535782716e98df07700851b26e00e8e4dd07d8fd5935090fb8e6>

# now if u wanna to list all running containers on ur machine.
$ docker container ls

# to stop container
$ docker container stop <container_id>
# after submit the command above it will return the container id that u used..

# to list all running and stopped containers
$ docker containers ls -a

						   .- run    --> start a new container always.
# run vs start container --|
						   .- start  --> start an existing container.  > docker container start <container_id>

# if we wanna to provide a meaningful name to our container
> docker container run --publiish 80:80 --detach --name <name> <image_name>

# now to see the log for a specific container 
> docker container logs <container_name> / <container_id>

# to see process running inside ur container.
> docker container top <container_id>

# to remove the unwanted containers use
> docker container rm <container_id 1> <container_id 2> ... <container_id etc>

# u can't remove running container, u will get error and ask u to stop the container.

# if u r sure that u wanna to remove a running container in this case use -f --> force
> docker container rm -f <container_id>

# let's take a look on the internal process when we run a container.
 - looks for the image in the image cache
 - then looks in the remote docker repo <default hub.docker.com>
 - download the latest version of the image.
 - create new container based on the image.
 - gives it a virtual IP on private network inside docker engine.
 - open port 80 on host machine and rout to port 80 inside container.
 - start container by using CMD in imager docker file.

# keep in mind the containers virtualize the O.S. but the vms virtulize the hardware.

# if for example we are looking for how many processors working on a host machine.
$ ps aux

# if u wanna to stop container u can use 3 or 4 first digits of container id and docker will verify the rest.

# if u wanna to explor docker commands u can use the command below:
$ docker --help


-----------------------------------------------------------------Assignments----------------------------------------------------

# The docker assignment:- 
 - run nginx, mysql and apache server
 - all containers must run in background
 - provide name to all containers
 - start nginx on port 80:80
 - start mysql on port 3306:3306
 - start apache server on port 8080:80   --> u will find the search result it's name httpd :)

# let's start with nginx
$ docker container run -d -p 80:80 --name proxyserver nginx  <-- the first port will be open on the host machine and the second port on the container.

# -d == --detach and -p == --port 

# let's start now the apache server
$ docker container run -d -p 8080:80 --name webserver httpd

# let's start now the mysql server, there's some notes we need to take care of.
 - use --env to pass the environment variable (MYSQL_RANDOM_ROOT_PASSWORD=yes)
 - use docker container logs command on mysql to find the random password created on start-up
$ docker container run -d -p 3306:3306 --name mysqldb --env MYSQL_RANDOM_ROOT_PASSWORD=yes mysql
$ docker container logs mysqldb  --> to get the password (thiephohLahkohk6eepaweexaxohh8ea)

---------------------------------------------------------------CLI Monitoring---------------------------------------------------

# to see what's going inside the running container
$ docker container top <continer_id/container_name> --> procees list in the container

# the old fashon of <docker container ls> is <docker ps> 

# to get the details about a container configuration
$ docker container inspect <continer_id/container_name>  ==> The result will be a json file :)

# to get performance states on all containers
$ docker container stats 

# if u waana to get inside a container and do so modification.
# the first step we need to run the container in <interactive mode>
> docker container run -it --name <container_name> <image_name> <command> --> to get more help <docker container run --help>
$ docker container run -it --name webproxy nginx bash
# to exit just use
$ exit ---> and hit enter
# as soon as u exit this kind of container, container will be stop running.

# to see the interactive container use <docker container ls -a>

# now the challenge is how to execute command inside a running command :)
> docker container exec -it <continer_id/container_name>  <command> --> open running container interactivly.

$ docker container exec -it proxyserver touch /tmp/mustafa
$ docker container exec -it proxyserver bash
# now let's run new container as ubuntu.
$ docker container run -it ubuntu bash
# because of the distro above is very light so we need to install the full package
$ apt-get update
$ apt-get install curl
# curl https://www.facebook.com

> docker exec  											  			--> run new command in a running container.

-------------------------------------------------------------Docker Networking--------------------------------------------------

# it will be unusful to use docker individually. 
# each container connect to virtual private network called "bridge".
# bridge is a docker default network driver <software>.
# containers on same bridge can communicate with each other without port. 
# containers in different bridges can't talk to each other.
# u r allow to create multiple VPN in docker.
# u can create multiple rules for single network.
# u can attach multiple containers to one network, u can attach one container to multiple networks and u can do no attach for a container to any network.

# to start container with allowing traffic from port on host machine.
> docker container run -p <host_port> : <docker_port> -d image

# to find traffic and protocol on a container.
> docker port <container_id>

# to find docker container ip
> docker inspect <container_id>

# ex:
$ docker container run -p 8080:80 -d nginx
$ ifconfig en0  <-- to get host machine ip
> copy the ip to the browser with host port --> <192.168.0.10:8080>
$ docker container port <container_id>
$ docker container inspect <container_id>  --> look for the "NetworkSettings" OR
$ docker container inspect -f '{{.NetworkSettings.IPAddress}}' e87c32600469    <-- container_id

# to list all available networks that the engine daemons knows about.
$ docker network ls

# to use filter for example to filter all bridges' networks
$ docker network -f drive=bridge

# to find all network IDs and drivers
$ docker network ls format "{{.ID}}:{{.Driver}}"    <-- it will return data in format of json.

# to get help on network command use
$ docker network --help

# to inspect any network
$ docker network inspect <network_id>  <-- returns information about one or more network in the format of json

# to create new network on a host machine.
$ docker network create <network_name> --> by default it will create a "bridge" network

# to create a bridge network 
$ docker network create -d bridge <bridge_name>

# now to connect a network with a container.
> docker network connect Network1 Container1   <-- container1 can by id or name.

# take a look on this example, this formula used when running container first time and we need to connect it to a network:
$ docker container run -p 8085:80 -d --name my_nginx --network myNetwork nginx  

# the next step u need to inspect both the network and then the container.

# now to connect a running machine to a network
$ docker network connect myNetwork kind_archimedes 
$ docker network inspect myNetwork
$ docker container inspect kind_archimedes <-- at this point u will see that this container had been connected to 2 networks

# to disconnect a container from a network use
> docker network disconnect Netowrk1 Container1
$ docker network disconnect bridge kind_archimedes

# if u disconnect a container from all networks, that's mean u will not be able to contact this container.

# containers use DNS to communicate.
# containers don't use IPs to communicate, instead they are using DNS.
$ docker container ls
$ docker network ls
$ docker network inspect myNetwork  <-- <myNetwork> is the name of the bridge that we already created.

# to use alpine version
$ docker container run -d --name mynginx_alpine_1 --network myNetwork nginx:alpine

# we will create 2 containers alpine and connect them both to the <myNetwork> then we will try to ping from container to another.
$ docker container exec -it mynginx_alpine ping mynginx_alpine_1


# why containers don't use IPs to communicate with each others because IPs are static in the container.
# and when u stop contaienr and start a new one, it may be using the same IP.

---------------------------------------------------------------Docker Images----------------------------------------------------

# image is a combination of a file system and parameters, images containe the binaries and dependencies.

# to list all docker images in ur machine.
$ docker images

# images don't contain O.S and O.S packages
# repository name is mean parent directory name ==> name of the file system u have :)

# if u don't specified the image version, client will defaults to the latest.

# docker images differenciation .-- Base Image: image that have no parent image --|- ubuntu
							    |												  |- busybox
								|                  								  |- debian
								|
								|-- Child Image: images that build on base images and add additional functinality 
								|-- Official Images: images that officialy maintend and support by the folks, one word long
								.-- User Images: images create and shared by users. user/image-name


# if u r looking for all official images, --> docker hub --> explore tab
# to dowanloa an image
> docker pull <image_name> : <image_version> 
$ docker pull mysql:5.7
$ docker images

# images in general consist of series of layers
# each layer has <union file system>
# docker use <union file systems> to combine these layers into a single image.
# union file systems allow files and directoris of sperate file systems, known as branch.

# to show image layers
> docker history <image_name>
$ docker history mysql
$ docker history nginx

# to get complete meta data of an image, 
> docker inspect <image_name>
$ docker inspect ngnix

# images have no name, 
# tag is specifing the tag of that particular repository.
# image id is the id generated when u push ur image over the docker hub.
# tag always associated with the latest image id.

									.-- tag add to the image during building time
# there're 2 ways to tag an image --|
									.-- tag explicitly using the tag command 

# tag command is 
> docker tag SOURCE_IMAGE[:TAG] TARGET_IMAGE[:TAG]
$ docker tag mysql:5.7 mysqlmustafa:test

# if u don't define any tag, by default takes "latest" tag :)

# do upload docker image to the docker hub u need account to do this
# docker cloud using docker hub as it's native registry for storing both public and private repos.

# to log into docker cloud from terminal u will use this command 
$ docker login   --> it will ask for your creds.
# one u enter the creds it will automatically encrypted and store in your machine.
# to view creds use
$ cat ~/.docker/config.json 

# one the you login successfully u can push the image to the cloud.

> docker image push USER(the account name)/image name

$ docker image push mysqlmustafa   <-- this will not be applied it will be denied coz of the tag.

# to resolve the issue above 
$ docker image tag mysql mustafakamil/mysqlmustafa

# now submit this command agin.
$ docker image push mustafakamil/mysqlmustafa   <-- this image will be accepted because it's not a single image name

# single image name allowed only for official docker image.

# if u wanna to add a tag to the uploaded image
$ docker image tag mustafakamil/mysqlmustafa  mustafakamil/mysqlmustafa:1.0.1
$ docker images

# after the command above u will see there's another image with this tag 1.0.1

# although the tags are different but the <image_id> are the same coze they are just a copy. :)

# now we need to push the image again.
$ docker image push mustafakamil/mysqlmustafa:1.0.1

# if u notice in the case above it will not upload all the image it will upload only the changes and that was the tag
# if there is any changes with filesystem in this case it will upload the whole image.

# now after u r done with all process above u need to logout using the command below
$ docker logout


------------------------------------------------------------Building Docker Images----------------------------------------------

# dockerfile which is a file will be used to create basic images or custome images.
# docker can build images automatically by reading the instructions from dockerfile

# dockerfile is a text document that contains all commands a user could call on the command line to assemble an image.

# docker image consist of read-only layers each of which represents a dockerfile instruction

# to build docker image from a dockerfile
> docker build -f <path_of_dokcerfile> 

# Dockerfile instructions are use to create the docker images.

# FROM: this instruction is used to initilize a new build stage and sets the base image from subsequent instructions.
# A valid dockerfile must start with a <FROM> nstruction
# Base image can be any valid image

# FROM instruction fromat 
> FROM <image>[:<tag>]

# LABEL: added to images to organize images by project, record licens information.
# for each label need to be added the line must have key-value pair.
# example:
> LABEL com.example.version='0.0.1-beta'
> LABEL vendore1='ACME Incorporated'    <-- another label.

# RUN: this instruction is used to execute any commands in new layer on top of the current image and commit the result.
# the resulting committed image will be used for the next step in the Dockerfile.

# Example:
FROM ubuntu:14.04
RUN apt-get update
RUN apt-get install -y curl


# CMD: this instruction should be used to run the software contained by ur image, along with any arguments.
# the format will be:
CMD ["executable","param1","param2"]

# can only be one CMD command in the dockerfile, if u list more than one command, the last one only will be effect.
# the purpose of the CMD command is to provide defaults for an executing container.

# EXPOSE: this instruction is used to indicates the ports on which a container listens for connection.
# the format will be:
EXPOSE <port>

#ENV: this instruction is used to sets the environment variables 
<Key> to the <Value>

# to make new software easier to run, u can use ENV to update the PATH environment variable for the software your container installes.

# ADD: this instruction is used to copies new files, directories or remote file URLs from <src> and add them to the filesystem of the image at the path <dest>.

# the format will be:
ADD hom*/mydir/   --> add all files starting with hom





















